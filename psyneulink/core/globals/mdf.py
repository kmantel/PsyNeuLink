"""

Contents
--------

  * `MDF_Overview`
  * `MDF_Examples`
  * `MDF_Model_Specification`

.. _MDF_Overview:


Overview
--------

The developers of PsyNeuLink are collaborating with the scientific community, as part of the `OpenNeuro effort
<https://openneuro.org>`_, to create a standard, serialzied format for the description and exchange of computational
models of brain and psychological function across different simulation environments. As part of this effort,
PsyNeuLink supports the `ModECI Model Description Format <https://github.com/ModECI/MDF/includes>`_ (MDF) by
including the ability to produce an MDF-compatible model from a PsyNeuLink model and to construct valid Python
scripts that express a PsyNeuLink model from an MDF model.

Any PsyNeuLink `Composition` or `Component` can be exported to MDF format using its `as_mdf_model` method or
to serialized format using its `json_summary` or `yaml_summary` methods. These methods generate strings that, passed into the
`generate_script_from_mdf` function, produce a valid Python script replicating the original PsyNeuLink model.
`write_mdf_file` can be used to write the serialization for one or more Compositions into a specified file (though
see `note <MDF_Write_Multiple_Compositions_Note>`). `generate_script_from_mdf` can accept either the string returned
by `get_mdf_serialized` or the name of a file containing one.
Calling ``exec(generate_script_from_mdf(<input>))`` will load into the current namespace all of the PsyNeuLink
objects specified in the ``input``; and `get_compositions` can be used to retrieve a list of all of the Compositions
in that namespace, including any generated by execution of `generate_script_from_mdf`. `generate_script_from_mdf`
may similarly be used to create a PsyNeuLink Python script from a ModECI MDF Model object, such as that created
by `as_mdf_model <Composition.as_mdf_model>`.

.. _MDF_Security_Warning:

.. warning::
   Use of `generate_script_from_json` or `generate_script_from_mdf` to generate a Python script from a file without taking proper precautions can
   introduce a security risk to the system on which the Python interpreter is running.  This is because it calls
   exec, which has the potential to execute non-PsyNeuLink-related code embedded in the file.  Therefore,
   `generate_script_from_json` or `generate_script_from_mdf` should be used to read only files of known and secure origin.

.. _MDF_Examples:

Model Examples
--------------

Below is an example of a script that implements a PsyNeuLink model of the Stroop model with conflict monitoring,
and its output in JSON. Running `generate_script_from_json` on the output will produce another PsyNeuLink script
that will give the same results when run on the same input as the original.

:download:`Download stroop_conflict_monitoring.py
<../../tests/mdf/stroop_conflict_monitoring.py>`

:download:`Download stroop_conflict_monitoring.json
<../../docs/source/_static/stroop_conflict_monitoring.json>`

.. _MDF_Model_Specification:

MDF Model Specification
------------------------

.. note::
    The format is in development, and is subject to change.

See https://github.com/ModECI/MDF/blob/main/docs/README.md#model


.. _MDF_Simple_Edge_Format:

MDF Simple Edge Format
----------------------

Models may be output as they are in PsyNeuLink or in "simple edge"
format. In simple edge format, PsyNeuLink Projections are written as a
combination of two Edges and an intermediate Node, because the generic
MDF execution engine does not support using Functions on Edges.
PsyNeuLink is capable of re-importing models exported by PsyNeuLink in
either form.
"""

import ast
import base64
import binascii
import copy
import dill
import enum
import functools
import graph_scheduler
import inspect
import json
import math
import numbers
import numpy
import os
import pickle
import pint
import psyneulink
import re
import tempfile
import types
import time
import warnings

from psyneulink.core.globals.keywords import \
    MODEL_SPEC_ID_GENERIC, MODEL_SPEC_ID_PARAMETER_SOURCE, \
    MODEL_SPEC_ID_PARAMETER_INITIAL_VALUE, MODEL_SPEC_ID_PARAMETER_VALUE, MODEL_SPEC_ID_PSYNEULINK, \
    MODEL_SPEC_ID_TYPE, MODEL_SPEC_ID_MDF_VARIABLE, MODEL_SPEC_ID_SHAPE, MODEL_SPEC_ID_METADATA, MODEL_SPEC_ID_INPUT_PORT_COMBINATION_FUNCTION
from psyneulink.core.globals.parameters import ParameterAlias
from psyneulink.core.globals.sampleiterator import SampleIterator
from psyneulink.core.globals.utilities import convert_to_list, gen_friendly_comma_str, get_all_explicit_arguments, \
    parse_string_to_psyneulink_object_string, parse_valid_identifier, safe_equals, convert_to_np_array

__all__ = [
    'MDFError', 'MDFSerializable', 'PNLJSONEncoder',
    'generate_json', 'generate_script_from_json', 'generate_script_from_mdf',
    'write_json_file', 'get_mdf_model', 'get_mdf_serialized', 'write_mdf_file'
]


# file extension to mdf common name
supported_formats = {
    'json': 'json',
    'yml': 'yaml',
    'yaml': 'yaml',
}

SCRIPT_INPUT_VARS_COMMENT_START = '# Input Ports exposed to user, with default values'
SCRIPT_INPUT_VARS_COMMENT_END = '# End Input Ports'


class MDFError(Exception):
    pass


class MDFSerializable:
    @property
    def json_summary(self):
        return self.as_mdf_model().to_json()

    @property
    def yaml_summary(self):
        return self.as_mdf_model().to_yaml()


# leaving this due to instructions in test_documentation_models
# (useful for exporting Composition results to JSON)
class PNLJSONEncoder(json.JSONEncoder):
    """
        A `JSONEncoder
        <https://docs.python.org/3/library/json.html#json.JSONEncoder>`_
        that parses `_dict_summary <Component._dict_summary>` output
        into a more JSON-friendly format.
    """
    def default(self, o):
        import modeci_mdf.mdf as mdf
        from psyneulink.core.components.component import Component, ComponentsMeta

        if isinstance(o, ComponentsMeta):
            return o.__name__
        elif isinstance(o, (type, types.BuiltinFunctionType)):
            if o.__module__ == 'builtins':
                # just give standard type, like float or int
                return f'{o.__name__}'
            elif o is numpy.ndarray:
                return f'{o.__module__}.array'
            else:
                # some builtin modules are internally "_module"
                # but are imported with "module"
                return f"{o.__module__.lstrip('_')}.{o.__name__}"
        elif isinstance(o, (enum.Enum, types.FunctionType, types.SimpleNamespace)):
            return str(o)
        elif isinstance(o, types.MethodType):
            return o.__qualname__
        elif o is NotImplemented:
            return None
        elif isinstance(o, Component):
            return o.name
        elif isinstance(o, SampleIterator):
            return f'{o.__class__.__name__}({repr(o.specification)})'
        elif isinstance(o, numpy.ndarray):
            return list(o)
        elif isinstance(o, numpy.random.RandomState):
            return f'numpy.random.RandomState({o.seed})'
        elif isinstance(o, numpy.number):
            return o.item()
        elif isinstance(o, mdf.BaseWithId):
            return json.loads(o.to_json())

        try:
            return super().default(o)
        except TypeError:
            return str(o)


def _get_variable_parameter_name(obj):
    try:
        if obj.parameters.variable.mdf_name is not None:
            return obj.parameters.variable.mdf_name
    except AttributeError:
        pass

    return MODEL_SPEC_ID_MDF_VARIABLE


def _mdf_obj_from_dict(d):
    import modeci_mdf.mdf as mdf

    def _get_mdf_object(obj, cls_):
        try:
            model_id = obj['id']
        except KeyError:
            try:
                model_id = obj['metadata']['name']
            except KeyError:
                model_id = f'{cls_.__name__}_{time.perf_counter_ns()}'

        return cls_.from_dict({model_id: obj})

    for cls_name in mdf.__all__:
        cls_ = getattr(mdf, cls_name)
        if all([attr.name in d or attr.name in {'id', 'parameters'} for attr in cls_.__attrs_attrs__]):
            return _get_mdf_object(d, cls_)

    if 'function' in d and 'args' in d:
        return _get_mdf_object(d, mdf.Function)

    # nothing else seems to fit, try Function (unreliable)
    if 'value' in d:
        return _get_mdf_object(d, mdf.Function)

    return None


@functools.lru_cache()
def _get_pnl_component_type(s):
    from psyneulink.core.components.component import ComponentsMeta

    try:
        return getattr(psyneulink, s)
    except AttributeError:
        for pnl_obj_name in dir(psyneulink):
            pnl_obj = getattr(psyneulink, pnl_obj_name)
            if s.lower() == pnl_obj_name.lower():
                if isinstance(pnl_obj, ComponentsMeta):
                    return pnl_obj
            else:
                try:
                    if pnl_obj._model_spec_generic_type_name.lower() == s.lower():
                        return pnl_obj
                except AttributeError:
                    pass

    return None


def _parse_component_type(model_obj):
    import modeci_mdf.mdf as mdf

    type_str = None
    type_dict = None
    try:
        try:
            type_dict = model_obj.metadata[MODEL_SPEC_ID_TYPE]
        except AttributeError:
            # could be a dict specification
            type_str = model_obj[MODEL_SPEC_ID_METADATA][MODEL_SPEC_ID_TYPE]
    except (IndexError, KeyError, TypeError):
        # specifically for functions the keyword is not 'type'
        type_str = model_obj.function

    if type_str is None:
        try:
            type_str = type_dict[MODEL_SPEC_ID_PSYNEULINK]
        except KeyError:
            # catch error outside of this function if necessary
            type_str = type_dict[MODEL_SPEC_ID_GENERIC]
        except TypeError:
            # actually a str
            type_str = type_dict

        if type_dict is None:
            if (
                isinstance(model_obj, mdf.Function)
                and model_obj.function is None
                and model_obj.value is not None
            ):
                return model_obj.value

    elif isinstance(type_str, dict):
        if len(type_str) != 1:
            raise MDFError
        else:
            elem = list(type_str.keys())[0]
            # not a function_type: args dict
            if MODEL_SPEC_ID_METADATA in type_str[elem]:
                raise MDFError
            else:
                type_str = elem

    # gets the actual psyneulink type (Component, etc..) from the module
    pctres = _get_pnl_component_type(type_str)
    if pctres is not None:
        return pctres

    try:
        from modeci_mdf.functions.standard import mdf_functions
        mdf_functions[type_str]['function']
    # remove import/module errors when modeci_mdf is a package
    except (ImportError, KeyError, ModuleNotFoundError):
        pass
    else:
        return f"modeci_mdf.functions.standard.mdf_functions['{type_str}']['function']"

    try:
        getattr(math, type_str)
    except (AttributeError, TypeError):
        pass
    else:
        return f'math.{type_str}'

    try:
        eval(type_str)
    except (TypeError, SyntaxError):
        pass
    except NameError:
        return type_str
    else:
        return type_str

    raise MDFError(f'Invalid type specified for MDF object: {model_obj}')


def _parse_parameter_value(value, component_identifiers=None, name=None, parent_parameters=None):
    import modeci_mdf.mdf as mdf

    if component_identifiers is None:
        component_identifiers = {}

    exec('import numpy')
    try:
        pnl_type = _parse_component_type(value)
    except (AttributeError, TypeError, MDFError):
        # ignore parameters that aren't components
        pnl_type = None

    if isinstance(value, list):
        with warnings.catch_warnings():
            warnings.simplefilter(action='error', category=numpy.VisibleDeprecationWarning)
            try:
                as_np_array = numpy.array(value)
            except numpy.VisibleDeprecationWarning:
                pass
            else:
                if as_np_array.dtype == float or as_np_array.dtype == int:
                    return _parse_parameter_value(as_np_array, component_identifiers, name, parent_parameters)

        new_val = [_parse_parameter_value(x, component_identifiers, name, parent_parameters) for x in value]

        # check for ParameterPort spec
        if (
            len(value) == 2
            and isinstance(value[0], (numbers.Number, numpy.ndarray))
            and isinstance(value[1], dict)
        ):
            # make tuple instead of list
            value = f"({', '.join([str(x) for x in new_val])})"
        else:
            value = f"[{', '.join([str(x) for x in new_val])}]"
    elif isinstance(value, dict):
        if (
            MODEL_SPEC_ID_PARAMETER_SOURCE in value
            and MODEL_SPEC_ID_PARAMETER_VALUE in value
        ):
            # handle ParameterPort spec
            try:
                value_type = eval(value[MODEL_SPEC_ID_TYPE])
            except Exception as e:
                raise MDFError(
                    'Invalid python type specified in MDF object: {0}'.format(
                        value[MODEL_SPEC_ID_TYPE]
                    )
                ) from e

            value = _parse_parameter_value(
                value[MODEL_SPEC_ID_PARAMETER_VALUE],
                component_identifiers,
                name,
                parent_parameters,
            )

            # handle tuples and numpy arrays, which both are dumped
            # as lists in JSON form
            if value_type is tuple:
                # convert list brackets to tuple brackets
                assert value[0] == '[' and value[-1] == ']'
                value = f'({value[1:-1]})'
            elif value_type is numpy.ndarray:
                value = f'{value[MODEL_SPEC_ID_TYPE]}({value})'
        elif MODEL_SPEC_ID_PARAMETER_INITIAL_VALUE in value:
            # is a stateful parameter with initial value
            value = _parse_parameter_value(
                value[MODEL_SPEC_ID_PARAMETER_INITIAL_VALUE],
                component_identifiers,
                name,
                parent_parameters
            )
        elif MODEL_SPEC_ID_PARAMETER_VALUE in value and pnl_type is None:
            # is a standard mdf Parameter class with value
            value = _parse_parameter_value(
                value[MODEL_SPEC_ID_PARAMETER_VALUE],
                component_identifiers,
                name,
                parent_parameters
            )
        else:
            if len(value) == 1:
                try:
                    identifier = list(value.keys())[0]
                except KeyError:
                    identifier = name

                mdf_object = value[identifier]
            else:
                try:
                    identifier = value['id']
                except KeyError:
                    identifier = name

                mdf_object = value

            # it is either a Component spec or just a plain dict
            if (
                identifier in component_identifiers
                and component_identifiers[identifier]
            ):
                # if this spec is already created as a node elsewhere,
                # then just use a reference
                value = identifier
            else:
                if not isinstance(mdf_object, mdf.Base):
                    mdf_object = _mdf_obj_from_dict(mdf_object)

                try:
                    value = _generate_component_string(
                        mdf_object,
                        component_identifiers,
                        component_name=identifier,
                        parent_parameters=parent_parameters
                    )
                except (AttributeError, MDFError, KeyError, TypeError):
                    # standard dict handling
                    value = '{{{0}}}'.format(
                        ', '.join([
                            '{0}: {1}'.format(
                                str(_parse_parameter_value(k, component_identifiers, name)),
                                str(_parse_parameter_value(v, component_identifiers, k))
                            )
                            for k, v in value.items()
                        ])
                    )

    elif isinstance(value, str):
        # handle pointer to parent's parameter value
        try:
            return _parse_parameter_value(parent_parameters[value])
        except (KeyError, TypeError):
            pass

        # handle reference to psyneulink object
        obj_string = parse_string_to_psyneulink_object_string(value)
        if obj_string is not None:
            return f'psyneulink.{obj_string}'

        # handle dill string
        try:
            dill_str = base64.decodebytes(bytes(value, 'utf-8'))
            dill.loads(dill_str)
            return f'dill.loads({dill_str})'
        except (binascii.Error, pickle.UnpicklingError, EOFError):
            pass

        # handle IO port specification
        match = re.match(r'(.+)\.(.+)_ports\.(.+)', value)
        if match is not None:
            comp_name, port_type, name = match.groups()
            comp_identifer = parse_valid_identifier(comp_name)

            if comp_identifer in component_identifiers:
                name_as_kw = parse_string_to_psyneulink_object_string(name)
                if name_as_kw is not None:
                    name = f'psyneulink.{name_as_kw}'
                else:
                    name = f"'{name}'"

                return f'{comp_identifer}.{port_type}_ports[{name}]'

        # if value is just a non-fixed component name, use the fixed name
        identifier = parse_valid_identifier(value)
        if identifier in component_identifiers:
            value = identifier

        try:
            psyneulink._unit_registry.Unit(value)
        except (AttributeError, TypeError, ValueError, pint.errors.DefinitionSyntaxError):
            pass
        else:
            value = f"'{value}'"

        try:
            psyneulink._unit_registry.Quantity(value)
        except (AttributeError, TypeError, ValueError, pint.errors.DefinitionSyntaxError):
            pass
        else:
            value = f"'{value}'"

        evaluates = False
        try:
            eval(value, component_identifiers)
            evaluates = True
        except (TypeError, NameError, SyntaxError):
            pass

        try:
            eval(value)
            evaluates = True
        except (TypeError, NameError, SyntaxError):
            pass

        # handle generic string
        if (
            (value not in component_identifiers or name == 'name')
            # assume a string that contains a dot is a command, not a raw
            # string, this is definitely imperfect and can't handle the
            # legitimate case, but don't know how to distinguish..
            and '.' not in value
            and not evaluates
        ):
            value = f"'{value}'"

    elif isinstance(value, mdf.Base):
        value = _generate_component_string(
            value,
            component_identifiers,
            component_name=value.id,
            parent_parameters=parent_parameters
        )

    elif isinstance(value, numpy.ndarray):
        # arbitrarily choose 5 as max elements in array before
        # condensing uniform numpy arrays
        if value.size > 5:
            if (value == 0).all():
                return f"numpy.zeros({value.shape}, dtype='{value.dtype}')"
            elif (value == 1).all():
                return f"numpy.ones({value.shape}, dtype={value.dtype}')"
            else:
                try:
                    if all([dim == value.shape[0] for dim in value.shape]):
                        if (value == numpy.identity(value.shape[0])).all():
                            return f"numpy.identity({value.shape[0]}, dtype='{value.dtype}')"
                except IndexError:
                    pass

        value = value.tolist()

    return value


def _preprocess_substitute_function_args(graph):
    """
    Substitute the value of function args that reference a basic MDF
    parameter by name
    """
    for n in graph.nodes:
        for f in n.functions:
            if f.args is None:
                continue

            for arg_name, arg_value in f.args.items():
                for p in n.parameters:
                    # only handle non-stateful parameters here
                    if (
                        p.value is not None
                        and p.default_initial_value is None
                        and p.id == arg_value
                    ):
                        f.args[arg_name] = p.value

    return graph


def _preprocess_detect_model_user_inputs(graph):
    """
    Detect model user inputs (nodes that have inputs with no incoming
    edge)
    """
    ivars = {}
    for n in graph.nodes:
        for ip in n.input_ports:
            for e in graph.edges:
                if e.receiver == n.id and e.receiver_port == ip.id:
                    break
            else:
                ivars[ip.id] = numpy.zeros(ip.shape, dtype=ip.type)
    return graph, ivars


def _preprocess_matrix_multiply_nodes_into_projections(
    graph,
    input_vars,
    origin_node_as_projection=True,
    terminal_node_as_projection=True,
):
    """
    Detect nodes that can be rewritten as psyneulink projections.
    That is, nodes with:
        1. exactly one output port
        2. a single matrix multiply as function
        3. exactly one outgoing edge
        4.a either exactly one incoming edge
        4.b or two incoming edges, one of which leads to the matrix
            (onnx::MatMul 'B') parameter and maps to an input
            variable with optional onnx::Transpose operation

    Args:
        graph: mdf.Graph
        input_vars: dict: dictionary of model user inputs
        origin_node_as_projection: bool: if True, this function rewrites
            origin nodes as projections by adding a new passthrough
            origin node; if False, origin nodes that would otherwise be
            converted to projections are skipped
        terminal_node_as_projection: bool: if True, this function
            rewrites terminal nodes as projections by adding a new
            passthrough terminal node; if False, terminal nodes that
            would otherwise be converted to projections are skipped
    """
    import modeci_mdf.mdf as mdf

    def _get_matrix_arg(func_name):
        # referencing names through objects in case future refactoring
        if func_name == psyneulink.LinearMatrix.__name__:
            return psyneulink.LinearMatrix.parameters.matrix.name
        else:
            return psyneulink.LinearMatrix.parameters.matrix.mdf_name

    def _create_passthrough_node(origin: bool):
        if origin:
            new_term_id = f'{node.id}_passthrough_origin'
            shape = node.input_ports[0].shape
            typ = node.input_ports[0].type
        else:
            new_term_id = f'{node.id}_passthrough_terminal'
            shape = node.output_ports[0].shape
            typ = node.output_ports[0].type

        new_term_ip_id = f'{new_term_id}_input'
        new_term_func_id = f'{new_term_id}_function'
        return mdf.Node(
            id=new_term_id,
            input_ports=[
                mdf.InputPort(id=new_term_ip_id, shape=shape, type=typ),
            ],
            functions=[
                mdf.Function(
                    id=f'{new_term_func_id}',
                    value=new_term_ip_id,
                    args={},
                    metadata={
                        'type': psyneulink.Identity.__name__
                    }
                )
            ],
            output_ports=[
                mdf.OutputPort(
                    id=f'{new_term_id}_output',
                    shape=shape,
                    type=typ,
                    value=new_term_func_id,
                )
            ],
        )

    def _node_is_input_transpose(node):
        return (
            len(node.input_ports) == 1
            and len(node.functions) == 1
            and node.functions[0].function == 'onnx::Transpose'
            and node.input_ports[0].id in input_vars
        )

    # store {node: tuple} with elements:
    #   sender pathway edge
    #   receiver
    #   matrix input name
    nodes_to_replace_as_psyneulink_edges = {}
    for n in graph.nodes:
        # cond 1
        if len(n.output_ports) != 1:
            continue

        # cond 2
        if len(n.functions) != 1:
            continue

        function = n.functions[0]
        try:
            func_name = function.function
        except AttributeError:
            continue

        if func_name is None or _get_pnl_component_type(func_name) != psyneulink.LinearMatrix:
            continue

        incoming_edges = []
        outgoing_edge = None
        for e in graph.edges:
            if e.sender == n.id:
                assert e.sender_port == n.output_ports[0].id
                # cond 3
                if outgoing_edge is not None:
                    continue
                else:
                    outgoing_edge = e
            if e.receiver == n.id:
                incoming_edges.append(e)

        matrix_param_name = _get_matrix_arg(func_name)
        matrix_arg = function.args[matrix_param_name]
        # cond 4
        if len(incoming_edges) == 1:
            # search for psyneulink-generated node-as-edge
            if matrix_arg == incoming_edges[0].receiver_port:
                # only incoming projection is to the matrix
                sender_edge = None
                matrix_value_edge = incoming_edges[0]
            else:
                sender_edge = incoming_edges[0]
                matrix_value_edge = None

            # identify when only edge (to matrix) is an input-transpose
            try:
                sender = [x for x in graph.nodes if x.id == matrix_value_edge.sender][0]
            except (AttributeError, IndexError):
                pass
            else:
                if _node_is_input_transpose(sender):
                    matrix_arg = sender.input_ports[0].id

            nodes_to_replace_as_psyneulink_edges[n] = (sender_edge, matrix_value_edge, outgoing_edge, matrix_arg)
        elif len(incoming_edges) == 2:
            if incoming_edges[0].receiver_port == matrix_arg:
                matrix_value_edge = incoming_edges[0]
                sender_edge = incoming_edges[1]
            else:
                matrix_value_edge = incoming_edges[1]
                sender_edge = incoming_edges[0]

            if matrix_arg in input_vars:
                # matrix directly maps to an input variable, so can
                # transform this node
                nodes_to_replace_as_psyneulink_edges[n] = (sender_edge, matrix_value_edge, outgoing_edge, matrix_arg)
            else:
                # check that sender is a simple Transpose op leading to
                # an input variable
                try:
                    sender = [x for x in graph.nodes if x.id == matrix_value_edge.sender][0]
                except IndexError:
                    continue

                if _node_is_input_transpose(sender):
                    nodes_to_replace_as_psyneulink_edges[n] = (sender_edge, matrix_value_edge, outgoing_edge, sender.input_ports[0].id)

    for node, (incoming_edge, matrix_edge, outgoing_edge, matrix_arg) in nodes_to_replace_as_psyneulink_edges.items():
        if incoming_edge is None:
            if not origin_node_as_projection:
                continue
            else:
                new_origin_node = _create_passthrough_node(origin=True)
                incoming_edge = types.SimpleNamespace(
                    sender=new_origin_node.id,
                    sender_port=new_origin_node.output_ports[0].id
                )
                graph.nodes.append(new_origin_node)
        else:
            graph.edges.remove(incoming_edge)

        if outgoing_edge is None:
            if not terminal_node_as_projection:
                continue
            else:
                new_terminal_node = _create_passthrough_node(origin=False)
                outgoing_edge = types.SimpleNamespace(
                    receiver=new_terminal_node.id,
                    receiver_port=new_terminal_node.input_ports[0].id
                )
                graph.nodes.append(new_terminal_node)
        else:
            graph.edges.remove(outgoing_edge)

        edge_func_name = f'{node.id}_{psyneulink.LinearMatrix.__name__}'
        edge_func_metadata = {}
        if node.functions[0].args is not None:
            edge_func_metadata.update(node.functions[0].args)
        if node.functions[0].metadata is not None:
            edge_func_metadata.update(node.functions[0].metadata)
        try:
            # this would override matrix_arg specified in args/parameters
            del edge_func_metadata[psyneulink.LinearMatrix.parameters.matrix.mdf_name]
        except KeyError:
            pass

        # replace default variable referencing input port to array with its shape
        variable_key = psyneulink.LinearMatrix.parameters.variable.mdf_name
        try:
            ip = [x for x in node.input_ports if x.id == edge_func_metadata[variable_key]][0]
            edge_func_metadata[variable_key] = f"numpy.zeros({ip.shape}, dtype='{ip.type}')"
        except (IndexError, KeyError):
            pass

        if matrix_edge is not None:
            graph.edges.remove(matrix_edge)
            sender_node = [n for n in graph.nodes if n.id == matrix_edge.sender][0]
            if _node_is_input_transpose(sender_node):
                # do the transpose the node would have done manually
                ivar = input_vars[matrix_arg]
                del input_vars[matrix_arg]
                matrix_arg = f'{matrix_arg}_transpose'
                input_vars[matrix_arg] = ivar.transpose()
                graph.nodes.remove(sender_node)

        edge_metadata = {
            'functions': {
                edge_func_name: {
                    'metadata': edge_func_metadata,
                    'function': psyneulink.LinearMatrix._model_spec_generic_type_name,
                    psyneulink.LinearMatrix._model_spec_id_parameters: {
                        psyneulink.LinearMatrix.parameters.matrix.mdf_name: matrix_arg
                    }
                }
            }
        }

        new_edge = mdf.Edge(
            id=f'{node.id}_as_edge',
            sender=incoming_edge.sender,
            sender_port=incoming_edge.sender_port,
            receiver=outgoing_edge.receiver,
            receiver_port=outgoing_edge.receiver_port,
            metadata=edge_metadata
        )
        if node.metadata is not None:
            new_edge.metadata = {**node.metadata, **new_edge.metadata}

        graph.edges.append(new_edge)
        graph.nodes.remove(node)

    return graph, input_vars


def _preprocess_graph(graph):
    graph = copy.deepcopy(graph)
    input_vars = {}

    # TODO: add a processing level/specification on what types of
    # preprocessing to do

    graph = _preprocess_substitute_function_args(graph)  # should not be turned off
    graph, input_vars = _preprocess_detect_model_user_inputs(graph)
    graph, input_vars = _preprocess_matrix_multiply_nodes_into_projections(graph, input_vars)

    return graph, input_vars


def _generate_component_string(
    component_model,
    component_identifiers,
    component_name=None,
    parent_parameters=None,
    assignment=False,
    default_type=None   # used if no PNL or generic types are specified
):
    from psyneulink.core.components.functions.function import Function_Base
    from psyneulink.core.components.functions.userdefinedfunction import UserDefinedFunction

    try:
        component_type = _parse_component_type(component_model)
    except AttributeError as e:
        # acceptable to exclude type currently
        if default_type is not None:
            component_type = default_type
        else:
            raise type(e)(
                f'{component_model} has no PNL or generic type and no '
                'default_type is specified'
            ) from e

    if component_name is None:
        name = component_model.id
    else:
        name = component_name
        try:
            assert component_name == component_model.id
        except KeyError:
            pass

    is_user_defined_function = False
    try:
        parameters = dict(getattr(component_model, component_type._model_spec_id_parameters))
    except AttributeError:
        is_user_defined_function = True
    except TypeError:
        parameters = {}

    if is_user_defined_function or component_type is UserDefinedFunction:
        custom_func = component_type
        component_type = UserDefinedFunction
        try:
            parameters = dict(getattr(component_model, component_type._model_spec_id_parameters))
        except TypeError:
            parameters = {}
        parameters['custom_function'] = f'{custom_func}'
        try:
            del component_model.metadata['custom_function']
        except (KeyError, TypeError):
            pass

    try:
        parameters.update(getattr(component_model, component_type._model_spec_id_parameters))
    except TypeError:
        pass

    try:
        # args in function dict
        parameters.update(component_model.function[list(component_model.function.keys())[0]])
    except (AttributeError, KeyError):
        pass

    parameter_names = {}

    # TODO: remove this?
    # If there is a parameter that is the psyneulink identifier string
    # (as of this comment, 'pnl'), then expand these parameters as
    # normal ones. We don't check and expand for other
    # special strings here, because we assume that these are specific
    # to other modeling platforms.
    try:
        parameters.update(parameters[MODEL_SPEC_ID_PSYNEULINK])
        del parameters[MODEL_SPEC_ID_PSYNEULINK]
    except KeyError:
        pass

    try:
        functions = component_model.functions
    except AttributeError:
        try:
            functions = [_mdf_obj_from_dict(v) for k, v in component_model.metadata['functions'].items()]
        except (KeyError, TypeError):
            functions = None
        except AttributeError:
            functions = component_model.metadata['functions']

    # pnl objects only have one function unless specified in another way
    # than just "function"

    if functions is not None:
        dup_function_names = set([f.id for f in functions if f.id in component_identifiers])
        if len(dup_function_names) > 0:
            warnings.warn(
                f'Functions ({gen_friendly_comma_str(dup_function_names)}) of'
                f' {name} share names of mechanisms or compositions in this'
                ' model. This is likely to cause incorrect script reproduction.'
            )

        function_determined_by_output_port = False

        try:
            output_ports = component_model.output_ports
        except AttributeError:
            pass
        else:
            if len(output_ports) == 1 or isinstance(output_ports, list):
                try:
                    primary_output_port = output_ports[0]
                except KeyError:
                    primary_output_port = output_ports[list(output_ports)[0]]
                function_determined_by_output_port = True
            else:
                try:
                    # 'out_port' appears to be the general primary output_port term
                    # should ideally have a marker in mdf to define it as primary
                    primary_output_port = output_ports['out_port']
                except KeyError:
                    pass
                else:
                    function_determined_by_output_port = True

        # neuroml-style mdf has MODEL_SPEC_ID_PARAMETER_VALUE in output port definitions
        if function_determined_by_output_port and hasattr(primary_output_port, MODEL_SPEC_ID_PARAMETER_VALUE):
            parameter_names['function'] = re.sub(r'(.*)\[\d+\]', '\\1', getattr(primary_output_port, MODEL_SPEC_ID_PARAMETER_VALUE))
        else:
            parameter_names['function'] = [
                f.id for f in functions
                if not f.id.endswith(MODEL_SPEC_ID_INPUT_PORT_COMBINATION_FUNCTION)
            ][0]

        for f in functions + list(parameters.values()):
            try:
                if f.id == parameter_names['function']:
                    parameters['function'] = f
                    break
            except AttributeError:
                pass
        else:
            raise MDFError(f"Function {parameter_names['function']} expected for {name} but not found")

    assignment_str = f'{parse_valid_identifier(name)} = ' if assignment else ''

    additional_arguments = []
    # get the nonvariable arg and keyword arguments for the component's
    # constructor
    constructor_arguments = get_all_explicit_arguments(
        component_type,
        '__init__'
    )

    # put name as first argument
    if 'name' in constructor_arguments:
        additional_arguments.append(f"name='{name}'")

    if parent_parameters is None:
        parent_parameters = {}
        try:
            if len(component_model.input_ports) == 1:
                parent_parameters['variable'] = numpy.zeros(
                    component_model.input_ports[0].shape,
                    dtype=component_model.input_ports[0].type
                )
        except (AttributeError, TypeError):
            pass

    parameters = {
        **parent_parameters,
        **parameters,
        **(component_model.metadata if component_model.metadata is not None else {})
    }

    # MDF input ports do not have functions, so their shape is
    # equivalent to ours after the InputPort function is run (this
    # function may change the shape of the default variable), so ignore
    # the input port shape if input_ports parameter is specified
    if 'variable' not in parameters and 'input_ports' not in parameters:
        try:
            ip = getattr(parameters['function'], Function_Base._model_spec_id_parameters)[MODEL_SPEC_ID_MDF_VARIABLE]
            var = convert_to_np_array(
                numpy.zeros(ast.literal_eval(component_model.input_ports[ip][MODEL_SPEC_ID_SHAPE])),
                dimension=2
            ).tolist()
            parameters['variable'] = var
        except KeyError:
            pass

    if 'variable' not in parameters and 'input_ports' not in parameters:
        if hasattr(component_model, 'input_ports'):
            parameters['input_ports'] = [
                {'name': ip.id, 'variable': f"numpy.zeros({ip.shape}, dtype='{ip.type}')"}
                for ip in component_model.input_ports
            ]

    def parameter_value_matches_default(component_type, param, value):
        default_val = getattr(component_type.defaults, param)
        evaled_val = NotImplemented

        # see if val is a psyneulink class instantiation
        # if so, do not instantiate it (avoid offsetting rng for
        # testing - see if you can bypass another way?)
        try:
            eval(re.match(r'(psyneulink\.\w+)\(', value).group(1))
            is_pnl_instance = True
        except (AttributeError, TypeError, NameError, ValueError):
            is_pnl_instance = False

        if not is_pnl_instance:
            # val may be a string that evaluates to the default value
            # also skip listing in constructor in this case
            try:
                evaled_val = eval(value)
            except (TypeError, NameError, ValueError):
                pass
            except Exception:
                # Assume this occurred in creation of a Component
                # that probably needs some hidden/automatic modification.
                # Special handling here?
                # still relevant after testing for instance above?
                pass

        # skip specifying parameters that match the class defaults
        if (
            not safe_equals(value, default_val)
            and (
                evaled_val is NotImplemented
                or not safe_equals(evaled_val, default_val)
            )
        ):
            # test for dill use/equivalence
            try:
                is_dill_str = value[:5] == 'dill.'
            except TypeError:
                is_dill_str = False

            if (
                not is_dill_str
                or dill.dumps(eval(value)) != dill.dumps(default_val)
            ):
                return False

        return True

    mdf_names_to_pnl = {
        p.mdf_name: p.name for p in component_type.parameters
        if (
            p.mdf_name is not None and not isinstance(p, ParameterAlias)
            # use 'variable' from parent parameters if present
            and (p.name != 'variable' or 'variable' not in parameters)
        )
    }

    # sort on arg name
    for arg, val in sorted(parameters.items(), key=lambda p: p[0]):
        try:
            arg = mdf_names_to_pnl[arg]
        except KeyError:
            pass

        try:
            constructor_parameter_name = getattr(component_type.parameters, arg).constructor_argument
            # Some Parameters may be stored just to be replicated here, and
            # they may have different names than are used in the
            # constructor of the object.
            # Examples:
            #   Component.variable / default_variable
            #   ControlMechanism.output_ports / control
            if constructor_parameter_name is not None:
                constructor_arg = constructor_parameter_name
            else:
                constructor_arg = arg
        except AttributeError:
            constructor_arg = arg

        if constructor_arg in constructor_arguments:
            try:
                val = _parse_parameter_value(
                    val, component_identifiers,
                    name=parameter_names[constructor_arg],
                    parent_parameters=parent_parameters,
                )
            except KeyError:
                val = _parse_parameter_value(val, component_identifiers, name=constructor_arg, parent_parameters=parent_parameters)

            if (
                (arg in component_type.parameters or constructor_arg in component_type.parameters)
                and not parameter_value_matches_default(component_type, arg, val)
            ):
                additional_arguments.append(f'{constructor_arg}={val}')
        elif component_type is UserDefinedFunction:
            try:
                val[MODEL_SPEC_ID_PARAMETER_INITIAL_VALUE]
            except (KeyError, TypeError):
                pass
            else:
                # is a stateful parameter corresponding to this function
                if val[MODEL_SPEC_ID_PARAMETER_VALUE] == name:
                    additional_arguments.append(f"stateful_parameter='{arg}'")

            if arg != MODEL_SPEC_ID_MDF_VARIABLE:
                val = _parse_parameter_value(
                    val, component_identifiers, name=arg, parent_parameters=parent_parameters
                )

                try:
                    matches = parameter_value_matches_default(component_type, arg, val)
                except AttributeError:
                    matches = False

                if not matches:
                    additional_arguments.append(f'{constructor_arg}={val}')

    output = '{0}psyneulink.{1}{2}{3}{4}'.format(
        assignment_str,
        component_type.__name__,
        '(' if len(additional_arguments) > 0 else '',
        ', '.join(additional_arguments),
        ')' if len(additional_arguments) > 0 else '',
    )

    return output


def _generate_scheduler_string(
    scheduler_id,
    scheduler_model,
    component_identifiers,
    blacklist=[]
):
    if scheduler_model is None:
        return ''

    output = []

    for node, condition in scheduler_model.node_specific.items():
        if node not in blacklist:
            output.append(
                '{0}.add_condition({1}, {2})'.format(
                    scheduler_id,
                    parse_valid_identifier(node),
                    _generate_condition_string(
                        condition,
                        component_identifiers
                    )
                )
            )

    termination_str = []
    for scale, cond in scheduler_model.termination.items():
        termination_str.insert(
            1,
            'psyneulink.{0}: {1}'.format(
                f'TimeScale.{str.upper(scale)}',
                _generate_condition_string(cond, component_identifiers)
            )
        )

    output.append(
        '{0}.termination_conds = {{{1}}}'.format(
            scheduler_id,
            ', '.join(termination_str)
        )
    )

    return '\n'.join(output)


def _generate_condition_string(condition_model, component_identifiers):
    def _parse_condition_arg_value(value):
        try:
            identifier = parse_valid_identifier(value)
        except TypeError:
            pass
        else:
            if identifier in component_identifiers:
                return str(identifier)

        try:
            getattr(psyneulink.core.scheduling.condition, value.type)
        except (AttributeError, KeyError, TypeError):
            pass
        else:
            return _generate_condition_string(value, component_identifiers)

        # handle value/outputport fix for threshold
        try:
            if re.match(r'\w+_OutputPort_0', value):
                return '"value"'
        except TypeError:
            pass

        return str(_parse_parameter_value(value, component_identifiers))

    def _parse_graph_scheduler_type(typ):
        for ts, pnl_ts in graph_scheduler.time._time_scale_aliases.items():
            ts_class_name = graph_scheduler.time._time_scale_to_class_str(ts)
            pnl_ts_class_name = graph_scheduler.time._time_scale_to_class_str(pnl_ts)

            if ts_class_name in typ:
                return typ.replace(ts_class_name, pnl_ts_class_name)

        return typ

    args_str = ''
    cond_type = _parse_graph_scheduler_type(condition_model.type)
    sig = inspect.signature(getattr(psyneulink, cond_type).__init__)

    var_positional_arg_name = None

    for name, param in sig.parameters.items():
        if param.kind is inspect.Parameter.VAR_POSITIONAL:
            var_positional_arg_name = name
            break

    args_dict = condition_model.kwargs

    try:
        pos_args = args_dict[var_positional_arg_name]
    except KeyError:
        pass
    else:
        if len(pos_args) > 0:
            arg_str_list = []
            for arg in pos_args:
                # handle nested Conditions
                try:
                    arg = _generate_condition_string(arg, component_identifiers)
                except TypeError:
                    pass

                arg_str_list.append(_parse_condition_arg_value(arg))
            args_str = f", {', '.join(arg_str_list)}"

    kwargs_str = ''
    kwargs = {k: v for k, v in args_dict.items() if k not in {'function', var_positional_arg_name}}
    if len(kwargs) > 0:
        kwarg_str_list = []
        for key, val in kwargs.items():
            kwarg_str_list.append(f'{key}={_parse_condition_arg_value(val)}')
        kwargs_str = f", {', '.join(kwarg_str_list)}"

    if 'function' in args_dict and args_dict['function'] is not None:
        func_str = args_dict['function']
    else:
        func_str = ''

    arguments_str = '{0}{1}{2}'.format(
        func_str,
        args_str,
        kwargs_str
    )
    if len(arguments_str) > 0 and arguments_str[0] == ',':
        arguments_str = arguments_str[2:]

    return f'psyneulink.{cond_type}({arguments_str})'


def _generate_composition_string(graph, component_identifiers):
    import modeci_mdf.mdf as mdf

    # used if no generic types are specified
    default_composition_type = psyneulink.Composition
    default_node_type = psyneulink.ProcessingMechanism
    default_edge_type = psyneulink.MappingProjection

    control_mechanism_types = (psyneulink.ControlMechanism, )
    # these are not actively added to a Composition
    implicit_types = (
        psyneulink.ObjectiveMechanism,
        psyneulink.ControlProjection,
        psyneulink.AutoAssociativeProjection,
        psyneulink.LearningMechanism,
        psyneulink.LearningProjection,
    )
    output = []

    comp_identifer = parse_valid_identifier(graph.id)

    def alphabetical_order(items):
        alphabetical = enumerate(
            sorted(items)
        )
        return {
            parse_valid_identifier(item[1]): item[0]
            for item in alphabetical
        }

    # get order in which nodes were added
    # may be node names or dictionaries
    try:
        node_order = graph.metadata['node_ordering']
        node_order = {
            parse_valid_identifier(list(node.keys())[0]) if isinstance(node, dict)
            else parse_valid_identifier(node): node_order.index(node)
            for node in node_order
        }

        unspecified_node_order = {
            node: position + len(node_order)
            for node, position in alphabetical_order([
                parse_valid_identifier(n.id) for n in graph.nodes if n.id not in node_order
            ]).items()
        }

        node_order.update(unspecified_node_order)

        assert all([
            (parse_valid_identifier(node.id) in node_order)
            for node in graph.nodes
        ])
    except (KeyError, TypeError, AssertionError):
        # if no node_ordering attribute exists, fall back to
        # alphabetical order
        node_order = alphabetical_order([parse_valid_identifier(n.id) for n in graph.nodes])

    keys_to_delete = []

    for node in graph.nodes:
        try:
            component_type = _parse_component_type(node)
        except (AttributeError, KeyError):
            # will use a default type
            pass
        else:
            # projection was written out as a node for simple_edge_format
            if issubclass(component_type, psyneulink.Projection_Base):
                assert len(node.input_ports) == 1
                assert len(node.output_ports) == 1

                extra_projs_to_delete = set()

                sender = None
                sender_port = None
                receiver = None
                receiver_port = None

                for proj in graph.edges:
                    if proj.receiver == node.id:
                        assert 'dummy' in proj.id
                        sender = proj.sender
                        sender_port = proj.sender_port
                        extra_projs_to_delete.add(proj.id)

                    if proj.sender == node.id:
                        assert 'dummy' in proj.id
                        receiver = proj.receiver
                        receiver_port = proj.receiver_port
                        # if for some reason the projection has node as both sender and receiver
                        # this is a bug, let the deletion fail
                        extra_projs_to_delete.add(proj.id)

                if sender is None:
                    raise MDFError(f'Dummy node {node.id} for projection has no sender in projections list')

                if receiver is None:
                    raise MDFError(f'Dummy node {node.id} for projection has no receiver in projections list')

                main_proj = mdf.Edge(
                    id=node.id.rstrip('_dummy_node'),
                    sender=sender,
                    receiver=receiver,
                    sender_port=sender_port,
                    receiver_port=receiver_port,
                    metadata={
                        **node.metadata,
                        'functions': node.functions
                    }
                )
                proj.parameters = {p.id: p for p in node.parameters}
                graph.edges.append(main_proj)

                keys_to_delete.append(node.id)
                for p in extra_projs_to_delete:
                    del graph.edges[graph.edges.index([e for e in graph.edges if e.id == p][0])]

                for nr_item in ['required_node_roles', 'excluded_node_roles']:
                    nr_removal_indices = []

                    for i, (nr_name, nr_role) in enumerate(
                        graph.metadata[nr_item]
                    ):
                        if nr_name == node.id:
                            nr_removal_indices.append(i)

                    for i in nr_removal_indices:
                        del graph.metadata[nr_item][i]

    for name_to_delete in keys_to_delete:
        del graph.nodes[graph.nodes.index([n for n in graph.nodes if n.id == name_to_delete][0])]

    # generate string for Composition itself
    output.append(
        "{0} = {1}\n".format(
            comp_identifer,
            _generate_component_string(
                graph,
                component_identifiers,
                component_name=graph.id,
                default_type=default_composition_type
            )
        )
    )
    component_identifiers[comp_identifer] = True

    mechanisms = []
    compositions = []
    control_mechanisms = []
    implicit_mechanisms = []

    # add nested compositions and mechanisms in order they were added
    # to this composition
    for node in sorted(
        graph.nodes,
        key=lambda item: node_order[parse_valid_identifier(item.id)]
    ):
        if isinstance(node, mdf.Graph):
            compositions.append(node)
        else:
            try:
                component_type = _parse_component_type(node)
            except (AttributeError, KeyError):
                component_type = default_node_type
            identifier = parse_valid_identifier(node.id)
            if issubclass(component_type, control_mechanism_types):
                control_mechanisms.append(node)
                component_identifiers[identifier] = True
            elif issubclass(component_type, implicit_types):
                implicit_mechanisms.append(node)
            else:
                mechanisms.append(node)
                component_identifiers[identifier] = True

    implicit_names = [node.id for node in implicit_mechanisms + control_mechanisms]

    for mech in mechanisms:
        try:
            mech_type = _parse_component_type(mech)
        except (AttributeError, KeyError):
            mech_type = None

        if (
            isinstance(mech_type, type)
            and issubclass(mech_type, psyneulink.Function)
        ):
            # removed branch converting functions defined as nodes
            # should no longer happen with recent MDF versions
            assert False

        output.append(
            _generate_component_string(
                mech,
                component_identifiers,
                component_name=parse_valid_identifier(mech.id),
                assignment=True,
                default_type=default_node_type
            )
        )
    if len(mechanisms) > 0:
        output.append('')

    for mech in control_mechanisms:
        output.append(
            _generate_component_string(
                mech,
                component_identifiers,
                component_name=parse_valid_identifier(mech.id),
                assignment=True,
                default_type=default_node_type
            )
        )

    if len(control_mechanisms) > 0:
        output.append('')

    # recursively generate string for inner Compositions
    for comp in compositions:
        output.append(
            _generate_composition_string(
                comp,
                component_identifiers
            )
        )
    if len(compositions) > 0:
        output.append('')

    # generate string to add the nodes to this Composition
    try:
        node_roles = {
            parse_valid_identifier(node): role for (node, role) in
            graph.metadata['required_node_roles']
        }
    except (KeyError, TypeError):
        node_roles = []

    try:
        excluded_node_roles = {
            parse_valid_identifier(node): role for (node, role) in
            graph.metadata['excluded_node_roles']
        }
    except (KeyError, TypeError):
        excluded_node_roles = []

    # do not add the controller as a normal node
    try:
        controller_name = graph.metadata['controller']['id']
    except (AttributeError, KeyError, TypeError):
        controller_name = None

    for node in sorted(
        graph.nodes,
        key=lambda item: node_order[parse_valid_identifier(item.id)]
    ):
        name = node.id
        if (
            name not in implicit_names
            and name != controller_name
        ):
            name = parse_valid_identifier(name)

            output.append(
                '{0}.add_node({1}{2})'.format(
                    comp_identifer,
                    name,
                    ', {0}'.format(
                        _parse_parameter_value(
                            node_roles[name],
                            component_identifiers
                        )
                    ) if name in node_roles else ''
                )
            )
    if len(graph.nodes) > 0:
        output.append('')

    if len(excluded_node_roles) > 0:
        for node_name, roles in excluded_node_roles.items():
            if node_name not in implicit_names and node_name != controller_name and node_name in [n.id for n in graph.nodes]:
                output.append(
                    f'{comp_identifer}.exclude_node_roles({node_name}, {_parse_parameter_value(roles, component_identifiers)})'
                )
        output.append('')

    # generate string to add the projections
    for proj in graph.edges:
        try:
            projection_type = _parse_component_type(proj)
        except (AttributeError, KeyError):
            projection_type = default_edge_type

        if (
            not issubclass(projection_type, implicit_types)
            and proj.sender not in implicit_names
            and proj.receiver not in implicit_names
        ):
            output.append(
                '{0}.add_projection(projection={1}, sender={2}, receiver={3})'.format(
                    comp_identifer,
                    _generate_component_string(
                        proj,
                        component_identifiers,
                        default_type=default_edge_type
                    ),
                    parse_valid_identifier(proj.sender),
                    parse_valid_identifier(proj.receiver),
                )
            )

    # add controller if it exists (must happen after projections)
    if controller_name is not None:
        output.append(
            '{0}.add_controller({1})'.format(
                comp_identifer,
                parse_valid_identifier(controller_name)
            )
        )

    # add schedulers
    # blacklist automatically generated nodes because they will
    # not exist in the script namespace
    output.append('')
    output.append(
        _generate_scheduler_string(
            f'{comp_identifer}.scheduler',
            graph.conditions,
            component_identifiers,
            blacklist=implicit_names
        )
    )

    return output


def generate_script_from_json(model_input, outfile=None):
    """
        Generate a Python script from JSON **model_input** in the
        `general JSON format <JSON_Model_Specification>`

        .. warning::
           Use of `generate_script_from_json` to generate a Python script from a file without taking proper precautions
           can introduce a security risk to the system on which the Python interpreter is running.  This is because it
           calls exec, which has the potential to execute non-PsyNeuLink-related code embedded in the file.  Therefore,
           `generate_script_from_json` should be used to read only files of known and secure origin.

        Arguments
        ---------

            model_input : str
                a JSON string in the proper format, or a filename
                containing such

        Returns
        -------

            Text of Python script : str



    """
    warnings.warn(
        'generate_script_from_json is replaced by generate_script_from_mdf and will be removed in a future version',
        FutureWarning
    )
    return generate_script_from_mdf(model_input, outfile)


def generate_script_from_mdf(model_input, outfile=None):
    """
        Generate a Python script from MDF model **model_input**

        .. warning::
           Use of `generate_script_from_mdf` to generate a Python script from a model without taking proper precautions
           can introduce a security risk to the system on which the Python interpreter is running.  This is because it
           calls exec, which has the potential to execute non-PsyNeuLink-related code embedded in the file.  Therefore,
           `generate_script_from_mdf` should be used to read only model of known and secure origin.

        Arguments
        ---------

            model_input : modeci_mdf.Model

        Returns
        -------

            Text of Python script : str
    """
    import modeci_mdf.mdf as mdf
    from modeci_mdf.utils import load_mdf

    def get_declared_identifiers(model):
        names = set()

        for graph in model.graphs:
            names.add(parse_valid_identifier(graph.id))
            for node in graph.nodes:
                if isinstance(node, mdf.Graph):
                    names.update(get_declared_identifiers(graph))

                names.add(parse_valid_identifier(node.id))

        return names

    if isinstance(model_input, mdf.Model):
        model = model_input
    else:
        # accept either json string or filename
        try:
            model = load_mdf(model_input)
        except (FileNotFoundError, OSError, ValueError) as e:
            try:
                model = mdf.Model.from_json(model_input)
            except json.decoder.JSONDecodeError:
                # assume yaml
                # delete=False because of problems with reading file on windows
                with tempfile.NamedTemporaryFile(
                    mode='w', suffix='.yml', delete=False
                ) as f:
                    try:
                        f.write(model_input)
                        model = load_mdf(f.name)
                    except Exception:
                        raise e

    imports_str = ''
    comp_strs = []
    # maps declared names to whether they are accessible in the script
    # locals. that is, each of these will be names specified in the
    # composition and subcomposition nodes, and their value in this dict
    # will be their actual value or True if they can be referenced by
    # this name in the script, and False otherwise
    component_identifiers = {
        i: False
        for i in get_declared_identifiers(model)
    }
    input_vars = {}
    processed_graphs = []

    for graph in model.graphs:
        graph, ivars = _preprocess_graph(graph)
        input_vars.update(ivars)
        processed_graphs.append(graph)

    component_identifiers.update(input_vars)

    for graph in processed_graphs:
        comp_strs.append(_generate_composition_string(graph, component_identifiers))

    input_vars_str = [f'{k} = numpy.zeros({v.shape}, dtype="{v.dtype}")' for k, v in input_vars.items()]
    if len(input_vars_str) > 0:
        input_vars_str.insert(0, SCRIPT_INPUT_VARS_COMMENT_START)
        input_vars_str.append(SCRIPT_INPUT_VARS_COMMENT_END)
        input_vars_str.append('')
    comp_strs.insert(0, input_vars_str)

    module_friendly_name_mapping = {
        'psyneulink': 'pnl',
        'dill': 'dill',
        'numpy': 'np'
    }

    potential_module_names = set()
    module_names = set()
    model_output = []

    for i in range(len(comp_strs)):
        # greedy and non-greedy
        for cs in comp_strs[i]:
            potential_module_names = potential_module_names.union(set([
                *re.findall(r'([A-Za-z_\.]+)\.', cs),
                *re.findall(r'([A-Za-z_\.]+?)\.', cs)
            ]))
            if 'modeci_mdf.functions.standard' in cs:
                potential_module_names.add('modeci_mdf.functions.standard')

        for module in potential_module_names:
            if module not in component_identifiers:
                try:
                    exec(f'import {module}')
                    module_names.add(module)
                except (ImportError, ModuleNotFoundError, SyntaxError):
                    pass

        for j in range(len(comp_strs[i])):
            for module in module_names.copy():
                try:
                    friendly_name = module_friendly_name_mapping[module]
                    comp_strs[i][j] = re.sub(f'{module}\\.', f'{friendly_name}.', comp_strs[i][j])
                except KeyError:
                    pass

        for m in module_names.copy():
            for n in module_names.copy():
                # remove potential modules that are substrings of another
                if m is not n and m in n:
                    module_names.remove(m)

        comp_strs[i] = '\n'.join(comp_strs[i])

    for module in sorted(module_names):
        try:
            friendly_name = module_friendly_name_mapping[module]
        except KeyError:
            friendly_name = module

        imports_str += 'import {0}{1}\n'.format(
            module,
            f' as {friendly_name}' if friendly_name != module else ''
        )

    outstr_elems = [imports_str, '\n'.join(comp_strs)]
    outstr_elems = list(filter(lambda e: e != '', outstr_elems))

    model_output = '\n'.join(outstr_elems)

    if outfile is not None:
        # pass through any file exceptions
        with open(outfile, 'w') as outfile:
            outfile.write(model_output)
            print(f'Wrote script to {outfile.name}')
    else:
        return model_output


def generate_json(*compositions, simple_edge_format=True):
    """
        Generate the `general JSON format <JSON_Model_Specification>`
        for one or more `Compositions <Composition>` and associated
        objects.
        .. _MDF_Write_Multiple_Compositions_Note:

        .. note::
           At present, if more than one Composition is specified, all
           must be fully disjoint;  that is, they must not share any
           `Components <Component>` (e.g., `Mechanism`, `Projections`
           etc.). This limitation will be addressed in a future update.

        Arguments:
            *compositions : Composition
                specifies `Composition` or iterable of ones to be output
                in JSON
    """
    warnings.warn(
        'generate_json is replaced by get_mdf_serialized and will be removed in a future version',
        FutureWarning
    )
    return get_mdf_serialized(*compositions, fmt='json', simple_edge_format=simple_edge_format)


def get_mdf_serialized(*compositions, fmt='json', simple_edge_format=True):
    """
        Generate the `general MDF serialized format <JSON_Model_Specification>`
        for one or more `Compositions <Composition>` and associated
        objects.

        .. note::
           At present, if more than one Composition is specified, all
           must be fully disjoint;  that is, they must not share any
           `Components <Component>` (e.g., `Mechanism`, `Projections`
           etc.). This limitation will be addressed in a future update.

        Arguments:
            *compositions : Composition
                specifies `Composition` or iterable of ones to be output
                in **fmt**

            fmt : str
                specifies file format of output. Current options ('json', 'yml'/'yaml')

            simple_edge_format : bool
                specifies use of
                `simple edge format <MDF_Simple_Edge_Format>` or not
    """
    model = get_mdf_model(*compositions, simple_edge_format=simple_edge_format)

    try:
        return getattr(model, f'to_{supported_formats[fmt]}')()
    except AttributeError as e:
        raise ValueError(
            f'Unsupported MDF output format "{fmt}". Supported formats: {gen_friendly_comma_str(supported_formats.keys())}'
        ) from e


def write_json_file(compositions, filename:str, path:str=None, simple_edge_format=True):
    """
        Write one or more `Compositions <Composition>` and associated objects to file in the `general JSON format
        <JSON_Model_Specification>`

        .. _MDF_Write_Multiple_Compositions_Note:

        .. note::
           At present, if more than one Composition is specified, all must be fully disjoint;  that is, they must not
           share  any `Components <Component>` (e.g., `Mechanism`, `Projections` etc.).  This limitation will be
           addressed in a future update.

        Arguments
        ---------
        compositions : Composition or list˚
             specifies `Composition` or list of ones to be written to **filename**

        filename : str
             specifies name of file in which to write JSON specification of `Composition(s) <Composition>`
             and associated objects.

        path : str : default None
             specifies path of file for JSON specification;  if it is not specified then the current directory is used.

    """
    warnings.warn(
        'write_json_file is replaced by write_mdf_file and will be removed in a future version',
        FutureWarning
    )
    write_mdf_file(compositions, filename, path, 'json', simple_edge_format)


def write_mdf_file(compositions, filename: str, path: str = None, fmt: str = None, simple_edge_format: bool = True):
    """
        Write the `general MDF serialized format <MDF_Model_Specification>`
        for one or more `Compositions <Composition>` and associated
        objects to file.

        .. note::
           At present, if more than one Composition is specified, all
           must be fully disjoint;  that is, they must not share any
           `Components <Component>` (e.g., `Mechanism`, `Projections`
           etc.). This limitation will be addressed in a future update.

        Arguments:
            compositions : Composition or list
                specifies `Composition` or list of ones to be written to
                **filename**

            filename : str
                specifies name of file in which to write MDF
                specification of `Composition(s) <Composition>` and
                associated objects.

            path : str : default None
                specifies path of file for MDF specification; if it is
                not specified then the current directory is used.

            fmt : str
                specifies file format of output. Current options ('json', 'yml'/'yaml')

            simple_edge_format : bool
                specifies use of
                `simple edge format <MDF_Simple_Edge_Format>` or not
    """
    compositions = convert_to_list(compositions)
    model = get_mdf_model(*compositions, simple_edge_format=simple_edge_format)

    if fmt is None:
        try:
            fmt = re.match(r'.*\.(.*)$', filename).groups()[0]
        except (AttributeError, IndexError):
            fmt = 'json'

    if path is not None:
        filename = os.path.join(path, filename)

    try:
        return getattr(model, f'to_{supported_formats[fmt]}_file')(filename)
    except AttributeError as e:
        raise ValueError(
            f'Unsupported MDF output format "{fmt}". Supported formats: {gen_friendly_comma_str(supported_formats.keys())}'
        ) from e


def get_mdf_model(*compositions, simple_edge_format=True):
    """
        Generate the MDF Model object for one or more
        `Compositions <Composition>` and associated objects.

        .. note::
           At present, if more than one Composition is specified, all
           must be fully disjoint;  that is, they must not share any
           `Components <Component>` (e.g., `Mechanism`, `Projections`
           etc.). This limitation will be addressed in a future update.

        Arguments:
            *compositions : Composition
                specifies `Composition` or iterable of ones to be output
                in the Model

            simple_edge_format : bool
                specifies use of
                `simple edge format <MDF_Simple_Edge_Format>` or not
    """
    import modeci_mdf
    import modeci_mdf.mdf as mdf
    from psyneulink.core.compositions.composition import Composition

    model_name = "_".join([c.name for c in compositions])

    model = mdf.Model(
        id=model_name,
        format=f'ModECI MDF v{modeci_mdf.__version__}',
        generating_application=f'PsyNeuLink v{psyneulink.__version__}',
    )

    for c in compositions:
        if not isinstance(c, Composition):
            raise MDFError(
                f'Item in compositions arg of {__name__}() is not a Composition: {c}.'
            )
        model.graphs.append(c.as_mdf_model(simple_edge_format=simple_edge_format))

    return model
