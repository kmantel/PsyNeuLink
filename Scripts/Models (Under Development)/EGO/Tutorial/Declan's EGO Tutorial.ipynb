{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules before executing code so we can modify modules and test without restarting kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "sys.path.append('..')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import run as run\n",
    "from models import *\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the EGO model and initialize its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Display the EGO model architecture\n",
    "model_image = Image.open('ego_model.png')\n",
    "display(model_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_recurrent_network(rnet, state_d, persistance=-0.6):\n",
    "    '''Prepare a recurrent context module that functions as a leaky integrator of the input state.\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        # Most weights/biases are set to zero or identity matrices here, except for the learnable output from context to EM.\n",
    "        rnet.state_to_hidden.weight.copy_(torch.eye(state_d, dtype=torch.float))\n",
    "        rnet.state_to_hidden.bias.zero_()\n",
    "        rnet.hidden_to_hidden.weight.zero_()\n",
    "        rnet.hidden_to_hidden.bias.zero_()\n",
    "        rnet.state_to_hidden_wt.weight.zero_()\n",
    "        # Set the integration constant (not exactly a leaky integrator, but close enough)\n",
    "        rnet.state_to_hidden_wt.bias.copy_(torch.ones((len(rnet.state_to_hidden_wt.bias),), dtype=torch.float) * persistance)\n",
    "        rnet.hidden_to_hidden_wt.weight.zero_()\n",
    "        rnet.hidden_to_hidden_wt.bias.zero_()\n",
    "        # Set hidden to context weights as an identity matrix.\n",
    "        rnet.hidden_to_context.weight.copy_(torch.eye(state_d, dtype=torch.float))\n",
    "        rnet.hidden_to_context.bias.zero_()\n",
    "\n",
    "    # Set requires_grad to True for hidden_to_context.weight before freezing other parameters\n",
    "    rnet.hidden_to_context.weight.requires_grad = True\n",
    "    rnet.hidden_to_context.bias.requires_grad = True\n",
    "\n",
    "    # Freeze recurrent weights to stabilize training\n",
    "    for name, p in rnet.named_parameters():\n",
    "        if 'hidden_to_context' not in name:\n",
    "            p.requires_grad = False\n",
    "        else:\n",
    "            p.requires_grad = True\n",
    "    return rnet\n",
    "\n",
    "# Hyperparameters for the CSW experiments.\n",
    "softmax_temperature = 0.1\n",
    "state_d = 11    # dimensionality of the input state vector\n",
    "context_d = 11  # dimensionality of the context vector (should be the same as the state vector for these experiments)\n",
    "persistance = -0.8  # how much of the incoming state information is integrated into the context\n",
    "\n",
    "# Initialize the recurrent context module.\n",
    "context_module = RecurrentContextModule(state_d, state_d, context_d)\n",
    "em_module = EMModule(softmax_temperature)\n",
    "context_module = prep_recurrent_network(context_module, state_d, persistance)\n",
    "print(context_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Generate some toy data for the CSW task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csw_img = Image.open('csw.png')\n",
    "display(csw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from datasets import CSWDataset\n",
    "\n",
    "probs = [1, 1, 1] # Probability of the context appropriate transition for the 2nd-4th state. Deterministic for now.\n",
    "contexts_to_load = [0,1,0,1,0]      # indices of the contexts for each trial (5 states per trial)\n",
    "n_samples_per_context = [1,1,1,1,1] # number of times to visit each context before transitioning\n",
    "ds = CSWDataset(n_samples_per_context, contexts_to_load, probs=probs)\n",
    "\n",
    "# Plot some example data from the CSW task.\n",
    "plt.imshow(ds.xs[:20], cmap='Greys', aspect='auto')\n",
    "for i, x in enumerate(np.linspace(0, 15, 4)):\n",
    "    plt.axhline(x-0.5, color='red', linestyle='--')\n",
    "    if i%2 == 0:\n",
    "        plt.text(5, x+1, 'Context 0', fontsize=16, color='blue')\n",
    "    else:\n",
    "        plt.text(5, x+1, 'Context 1', fontsize=16, color='darkorange')\n",
    "plt.axvline(8.5, color='red', linestyle='--')\n",
    "plt.xlabel('State', fontsize=14)\n",
    "plt.ylabel('Time', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import gen_data_loader, gen_model\n",
    "\n",
    "def calc_prob(em_preds, test_ys):\n",
    "    '''Calculate the probability of the EM model predicting the correct state through EM retrieval.\n",
    "    '''\n",
    "    # Only consider the terminal three states (they are the only predictable transitions).\n",
    "    em_preds_new, test_ys_new = em_preds[:, 2:-1, :], test_ys[:, 2:-1, :]\n",
    "    em_probability = (em_preds_new*test_ys_new).sum(-1).mean(-1)\n",
    "    trial_probs = (em_preds*test_ys)\n",
    "    return em_probability, trial_probs\n",
    "\n",
    "def run_participant(params, training_paradigm):\n",
    "    performance_data = {'seed':[], 'paradigm':[], 'trial':[], 'probability':[]}\n",
    "    loss_fn = nn.BCELoss()\n",
    "    data_loader = gen_data_loader(training_paradigm, params['probs'])\n",
    "    context_module, em_module = gen_model(params)\n",
    "    optimizer = torch.optim.SGD(lr=params.episodic_lr, params=context_module.parameters())\n",
    "    em_preds = []\n",
    "    utils.set_random_seed(params.seed)\n",
    "    for trial, (x,_,y) in enumerate(data_loader):\n",
    "        for _ in range(params['n_optimization_steps']):\n",
    "            context = context_module(x)\n",
    "            if trial > 0:\n",
    "                optimizer.zero_grad()\n",
    "                pred_em = em_module(x,context)\n",
    "                loss = loss_fn(pred_em,y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                pred_em = torch.zeros([1,params.output_d]).float()\n",
    "        with torch.no_grad():\n",
    "            em_module.write(x,context,y)\n",
    "            em_preds.append(pred_em.cpu().detach().numpy())\n",
    "\n",
    "    # Collect some metrics from the training run for analysis.\n",
    "    em_preds = np.stack(em_preds).squeeze()\n",
    "    em_preds = np.vstack([em_preds, np.zeros([1,11])]).reshape(-1,5,11)\n",
    "    test_ys = np.vstack([data_loader.dataset.ys.cpu().numpy(), np.zeros([1,11])]).reshape(-1,5,11)\n",
    "    correct_prob, _ = calc_prob(em_preds, test_ys)\n",
    "    performance_data['probability'].extend(correct_prob)\n",
    "    performance_data['seed'].extend([params.seed]*len(correct_prob))\n",
    "    performance_data['paradigm'].extend([training_paradigm]*len(correct_prob))\n",
    "    performance_data['trial'].extend(list(range(len(correct_prob))))\n",
    "    return pd.DataFrame(performance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters for the experiment.\n",
    "params = utils.Map(\n",
    "    n_participants = 1,\n",
    "    state_d = 11, # dimensionality of the state input\n",
    "    context_d = 11, # dimensionality of the learned context representations\n",
    "    output_d = 11, # dimensionality of the output layer\n",
    "    episodic_lr = 1, # learning rate for the episodic pathway\n",
    "    persistance = -0.8, # bias towards memory retention in the recurrent context module\n",
    "    temperature = 0.1, # temperature for EM retrieval (lower is more argmax-like)\n",
    "    n_optimization_steps = 10, # number of optimization steps to take for each state\n",
    "    probs = [1, 1, 1], # probability of the context appropriate transition for the 2nd-4th state\n",
    "    seed = 0 # random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Run a single participant through the CSW task using the Blocked paradigm.\n",
    "blocked_results = run_participant(params, 'Blocked')\n",
    "interleaved_results = run_participant(params, 'Interleaved')\n",
    "\n",
    "# Plot the performance of the model on the CSW task during the test phase\n",
    "results_df = pd.concat([blocked_results, interleaved_results])\n",
    "test_phase = results_df[results_df.trial >=160]\n",
    "sns.violinplot(data=test_phase, x='paradigm', y='probability', inner='point', scale='count')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel('Probability of Correct Prediction')\n",
    "plt.xlabel('Training Paradigm')\n",
    "plt.title('CSW Test Phase Performance')\n",
    "plt.axhline(0.5, color='black', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Put it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters for the experiment.\n",
    "params.n_participants = 10\n",
    "params.paradigms = ['Blocked', 'Interleaved']\n",
    "params.sim_thresh = 0.1  # filtering criterion that will be useful later.\n",
    "df, _, context_reps, _ = run.run_experiment(params)\n",
    "fig = utils.plot_results(df, 'Deterministic CSW')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
